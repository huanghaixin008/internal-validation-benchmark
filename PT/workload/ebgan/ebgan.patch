diff --git a/implementations/ebgan/ebgan.py b/implementations/ebgan/ebgan.py
index 0392930..c8646e4 100644
--- a/implementations/ebgan/ebgan.py
+++ b/implementations/ebgan/ebgan.py
@@ -13,26 +13,46 @@ from torch.autograd import Variable
 import torch.nn as nn
 import torch.nn.functional as F
 import torch
+import intel_pytorch_extension as ipex
+import time
 
 os.makedirs("images", exist_ok=True)
 
 parser = argparse.ArgumentParser()
-parser.add_argument("--n_epochs", type=int, default=200, help="number of epochs of training")
-parser.add_argument("--batch_size", type=int, default=64, help="size of the batches")
+parser.add_argument("--n_epochs", type=int, default=1, help="number of epochs of training")
+parser.add_argument("--batch_size", type=int, default=16, help="size of the batches")
 parser.add_argument("--lr", type=float, default=0.0002, help="adam: learning rate")
 parser.add_argument("--b1", type=float, default=0.5, help="adam: decay of first order momentum of gradient")
 parser.add_argument("--b2", type=float, default=0.999, help="adam: decay of first order momentum of gradient")
-parser.add_argument("--n_cpu", type=int, default=8, help="number of cpu threads to use during batch generation")
+parser.add_argument("--n_cpu", type=int, default=32, help="number of cpu threads to use during batch generation")
 parser.add_argument("--latent_dim", type=int, default=62, help="dimensionality of the latent space")
 parser.add_argument("--img_size", type=int, default=32, help="size of each image dimension")
 parser.add_argument("--channels", type=int, default=1, help="number of image channels")
-parser.add_argument("--sample_interval", type=int, default=400, help="number of image channels")
+parser.add_argument("--sample_interval", type=int, default=4, help="number of image channels")
+parser.add_argument('--outf', default='./model', help='folder to output images and model checkpoints')
+parser.add_argument('--inference', action='store_true', default=False)
+parser.add_argument('--num-iterations', default=10000, type=int)
+parser.add_argument('--ipex', action='store_true', default=False)
+parser.add_argument('--precision', default='float32', help='Precision, "float32" or "bfloat16"')
+parser.add_argument('--jit', action='store_true', default=False)
 opt = parser.parse_args()
 print(opt)
 
 img_shape = (opt.channels, opt.img_size, opt.img_size)
 
-cuda = True if torch.cuda.is_available() else False
+try:
+	os.makedirs(opt.outf)
+except OSError:
+	pass
+
+if opt.ipex:
+	if opt.precision == "bfloat16":
+		# Automatically mix precision
+		ipex.enable_auto_mixed_precision(mixed_dtype=torch.bfloat16)
+		print("Running with bfloat16...")
+	device = ipex.DEVICE
+else:
+	device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
 
 
 def weights_init_normal(m):
@@ -102,16 +122,11 @@ class Discriminator(nn.Module):
 
 
 # Reconstruction loss of AE
-pixelwise_loss = nn.MSELoss()
+pixelwise_loss = nn.MSELoss().to(device)
 
 # Initialize generator and discriminator
-generator = Generator()
-discriminator = Discriminator()
-
-if cuda:
-    generator.cuda()
-    discriminator.cuda()
-    pixelwise_loss.cuda()
+generator = Generator().to(device)
+discriminator = Discriminator().to(device)
 
 # Initialize weights
 generator.apply(weights_init_normal)
@@ -135,10 +150,30 @@ dataloader = torch.utils.data.DataLoader(
 # Optimizers
 optimizer_G = torch.optim.Adam(generator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))
 optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))
-
+cuda = torch.cuda.is_available()
 Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor
 
 
+def generate(netG, batchsize, device):
+	fixed_noise = Variable(Tensor(np.random.normal(0, 1, (img_shape[0], opt.latent_dim))))
+	dry_run = 5
+	netG.eval()
+	netG = netG.to(device=device)
+	if opt.jit:
+		netG = torch.jit.trace(netG, fixed_noise)
+
+	fixed_noise = fixed_noise.to(device=device)
+	tic = 0
+	with torch.no_grad():
+		for i in range(dry_run + opt.num_iterations):
+			if i == dry_run:
+				tic = time.time()
+			fake = netG(fixed_noise)
+
+	toc = time.time() - tic
+	print("Throughput: %.2f images/sec, batchsize: %d, latency = %.2f sec"%((opt.num_iterations*batchsize)/toc, batchsize, toc/opt.num_iterations))
+
+
 def pullaway_loss(embeddings):
     norm = torch.sqrt(torch.sum(embeddings ** 2, -1, keepdim=True))
     normalized_emb = embeddings / norm
@@ -148,6 +183,13 @@ def pullaway_loss(embeddings):
     return loss_pt
 
 
+if opt.inference:
+	print("----------------Generation benchmarking---------------")
+	generate(generator, opt.batch_size, device=torch.device(device))
+	import sys
+	sys.exit(0)
+
+
 # ----------
 #  Training
 # ----------
