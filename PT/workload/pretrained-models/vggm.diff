diff --git a/examples/imagenet_eval.py b/examples/imagenet_eval.py
index 8eb0555..6fe21e2 100644
--- a/examples/imagenet_eval.py
+++ b/examples/imagenet_eval.py
@@ -57,13 +57,42 @@ parser.add_argument('--do-not-preserve-aspect-ratio',
                     dest='preserve_aspect_ratio',
                     help='do not preserve the aspect ratio when resizing an image',
                     action='store_false')
+parser.add_argument('--mkldnn', action='store_true', default=False,
+                    help='use mkldnn weight cache')
+parser.add_argument('--jit', action='store_true', default=False,
+                    help='enable Intel_PyTorch_Extension JIT path')
+parser.add_argument('--cuda', action='store_true', default=False,
+                    help='disable CUDA')
+parser.add_argument('-i', '--iterations', default=0, type=int, metavar='N',
+                    help='number of total iterations to run')
+parser.add_argument('-w', '--warmup-iterations', default=0, type=int, metavar='N',
+                    help='number of warmup iterations to run')
+parser.add_argument('--precision', type=str, default="float32",
+                    help='precision, float32, int8, bfloat16')
+parser.add_argument("-t", "--profile", action='store_true',
+                    help="Trigger profile on current topology.")
+parser.add_argument("--performance", action='store_true',
+                    help="measure performance only, no accuracy.")
+parser.add_argument("--dummy", action='store_true',
+                    help="using  dummu data to test the performance of inference")
+
 parser.set_defaults(preserve_aspect_ratio=True)
 best_prec1 = 0
 
+args = parser.parse_args()
+assert not (args.mkldnn and args.cuda), "mkldnn and cuda can't be set together!"
+
+if args.mkldnn:
+    import intel_pytorch_extension as ipex
+    print("import IPEX **************")
+    if args.precision == "bfloat16":
+        # Automatically mix precision
+        ipex.enable_auto_mixed_precision(mixed_dtype = torch.bfloat16)
 
 def main():
     global args, best_prec1
     args = parser.parse_args()
+    print(args)
 
     # create model
     print("=> creating model '{}'".format(args.arch))
@@ -72,7 +101,7 @@ def main():
         model = pretrainedmodels.__dict__[args.arch](num_classes=1000,
                                                      pretrained=args.pretrained)
     else:
-        model = pretrainedmodels.__dict__[args.arch]()
+        model = pretrainedmodels.__dict__[args.arch](pretrained=None)
 
     # optionally resume from a checkpoint
     if args.resume:
@@ -87,7 +116,8 @@ def main():
         else:
             print("=> no checkpoint found at '{}'".format(args.resume))
 
-    cudnn.benchmark = True
+    if args.cuda:
+        cudnn.benchmark = True
 
     # Data loading code
     # traindir = os.path.join(args.data, 'train')
@@ -110,33 +140,51 @@ def main():
     # else:
     #     scale = 0.875
     scale = 0.875
+    opt = pretrainedmodels.pretrained_settings[args.arch]["imagenet"]
 
     print('Images transformed from size {} to {}'.format(
-        int(round(max(model.input_size) / scale)),
-        model.input_size))
+        int(round(max(opt["input_size"]) / scale)),
+        opt["input_size"]))
+    # print('Images transformed from size {} to {}'.format(
+    #     int(round(max(model.input_size) / scale)),
+    #     model.input_size))
 
     val_tf = pretrainedmodels.utils.TransformImage(
-        model,
+        opt,
         scale=scale,
         preserve_aspect_ratio=args.preserve_aspect_ratio
     )
-
-    val_loader = torch.utils.data.DataLoader(
-        datasets.ImageFolder(valdir, val_tf),
-        batch_size=args.batch_size, shuffle=False,
-        num_workers=args.workers, pin_memory=True)
+    if not args.dummy:
+        val_loader = torch.utils.data.DataLoader(
+            datasets.ImageFolder(valdir, val_tf),
+            batch_size=args.batch_size, shuffle=False,
+            num_workers=args.workers, pin_memory=True)
+    else:
+        val_loader=""
 
     # define loss function (criterion) and optimizer
-    criterion = nn.CrossEntropyLoss().cuda()
+    if args.cuda:
+        criterion = nn.CrossEntropyLoss().cuda()
+    else:
+        criterion = nn.CrossEntropyLoss()
 
     optimizer = torch.optim.SGD(model.parameters(), args.lr,
                                 momentum=args.momentum,
                                 weight_decay=args.weight_decay)
 
-    model = torch.nn.DataParallel(model).cuda()
+    if args.cuda:
+        model = torch.nn.DataParallel(model).cuda()
+    else:
+        model = torch.nn.DataParallel(model)
+    if args.mkldnn:
+        model = model.to(ipex.DEVICE)
 
     if args.evaluate:
-        validate(val_loader, model, criterion)
+        if args.jit:
+            scripted_model = torch.jit.script(model.eval())
+            validate(val_loader, scripted_model, criterion, args)
+        else:
+            validate(val_loader, model, criterion, args)
         return
 
     for epoch in range(args.start_epoch, args.epochs):
@@ -208,8 +256,10 @@ def train(train_loader, model, criterion, optimizer, epoch):
                 data_time=data_time, loss=losses, top1=top1, top5=top5))
 
 
-def validate(val_loader, model, criterion):
+def validate(val_loader, model, criterion, args):
     with torch.no_grad():
+        iterations = args.iterations
+        warmup = args.warmup_iterations
         batch_time = AverageMeter()
         losses = AverageMeter()
         top1 = AverageMeter()
@@ -218,36 +268,79 @@ def validate(val_loader, model, criterion):
         # switch to evaluate mode
         model.eval()
 
-        end = time.time()
-        for i, (input, target) in enumerate(val_loader):
-            target = target.cuda()
-            input = input.cuda()
-
-            # compute output
-            output = model(input)
-            loss = criterion(output, target)
-
-            # measure accuracy and record loss
-            prec1, prec5 = accuracy(output.data, target.data, topk=(1, 5))
-            losses.update(loss.data.item(), input.size(0))
-            top1.update(prec1.item(), input.size(0))
-            top5.update(prec5.item(), input.size(0))
-
-            # measure elapsed time
-            batch_time.update(time.time() - end)
-            end = time.time()
-
-            if i % args.print_freq == 0:
-                print('Test: [{0}/{1}]\t'
-                      'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\t'
-                      'Loss {loss.val:.4f} ({loss.avg:.4f})\t'
-                      'Acc@1 {top1.val:.3f} ({top1.avg:.3f})\t'
-                      'Acc@5 {top5.val:.3f} ({top5.avg:.3f})'.format(
-                       i, len(val_loader), batch_time=batch_time, loss=losses,
-                       top1=top1, top5=top5))
-
-        print(' * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'
-              .format(top1=top1, top5=top5))
+        if args.dummy:
+            image_size = pretrainedmodels.pretrained_settings[args.arch]["imagenet"]["input_size"]
+            images = torch.randn(args.batch_size, *image_size)
+            target = torch.arange(1, args.batch_size + 1).long()
+            # print("Start convert to onnx!")
+            # torch.onnx.export(model.module, images, args.arch + ".onnx", verbose=False)
+            # print("End convert to onnx!")
+            for i in range(iterations + warmup):
+                if i >= warmup:
+                    end = time.time()
+
+                if args.mkldnn:
+                    images = images.to(ipex.DEVICE)
+                elif args.cuda:
+                    images = images.cuda(args.gpu, non_blocking=True)
+                    target = target.cuda(args.gpu, non_blocking=True)
+
+                # compute output
+                output = model(images)
+
+                # measure elapsed time
+                if i >= warmup:
+                    batch_time.update(time.time() - end)
+
+                if i % args.print_freq == 0:
+                    print('Test: [{0}/{1}]'.format(i, iterations + warmup))
+        else:
+            for i, (input, target) in enumerate(val_loader):
+                if not args.evaluate or iterations == 0 or i < iterations + warmup:
+                    if i >= warmup:
+                        end = time.time()
+                    if args.mkldnn:
+                        input = input.to(ipex.DEVICE)
+                    elif args.cuda:
+                        target = target.cuda()
+                        input = input.cuda()
+
+                    # compute output
+                    output = model(input)
+                    loss = criterion(output, target)
+
+                    # measure accuracy and record loss
+                    prec1, prec5 = accuracy(output.data, target.data, topk=(1, 5))
+                    losses.update(loss.data.item(), input.size(0))
+                    top1.update(prec1.item(), input.size(0))
+                    top5.update(prec5.item(), input.size(0))
+
+                    # measure elapsed time
+                    if i >= warmup:
+                        batch_time.update(time.time() - end)
+                    end = time.time()
+
+                    if i % args.print_freq == 0:
+                        print('Test: [{0}/{1}]\t'
+                              'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\t'
+                              'Loss {loss.val:.4f} ({loss.avg:.4f})\t'
+                              'Acc@1 {top1.val:.3f} ({top1.avg:.3f})\t'
+                              'Acc@5 {top5.val:.3f} ({top5.avg:.3f})'.format(
+                               i, len(val_loader), batch_time=batch_time, loss=losses,
+                               top1=top1, top5=top5))
+                else:
+                    break
+
+            print(' * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'
+                  .format(top1=top1, top5=top5))
+
+        # TODO: this should also be done with the ProgressMeter
+        if args.evaluate:
+            batch_size = args.batch_size
+            latency = batch_time.avg / batch_size * 1000
+            perf = batch_size/batch_time.avg
+            print('inference latency: %3.3f ms'%latency)
+            print('inference Throughput: %3.3f fps'%perf)
 
         return top1.avg, top5.avg
 
@@ -301,4 +394,4 @@ def accuracy(output, target, topk=(1,)):
 
 
 if __name__ == '__main__':
-    main()
\ No newline at end of file
+    main()
diff --git a/pretrainedmodels/__init__.py b/pretrainedmodels/__init__.py
index 0187e4b..fdab0ba 100644
--- a/pretrainedmodels/__init__.py
+++ b/pretrainedmodels/__init__.py
@@ -53,3 +53,4 @@ from .models.senet import se_resnext50_32x4d
 from .models.senet import se_resnext101_32x4d
 from .models.pnasnet import pnasnet5large
 from .models.polynet import polynet
+from .models.vggm import vggm
diff --git a/pretrainedmodels/models/__init__.py b/pretrainedmodels/models/__init__.py
index 83c2392..2bafada 100644
--- a/pretrainedmodels/models/__init__.py
+++ b/pretrainedmodels/models/__init__.py
@@ -56,3 +56,5 @@ from .senet import se_resnext101_32x4d
 
 from .pnasnet import pnasnet5large
 from .polynet import polynet
+
+from .vggm import vggm
diff --git a/pretrainedmodels/models/utils.py b/pretrainedmodels/models/utils.py
index 4ef50b1..bc2799b 100644
--- a/pretrainedmodels/models/utils.py
+++ b/pretrainedmodels/models/utils.py
@@ -13,6 +13,7 @@ from .senet import pretrained_settings as senet_settings
 from .cafferesnet import pretrained_settings as cafferesnet_settings
 from .pnasnet import pretrained_settings as pnasnet_settings
 from .polynet import pretrained_settings as polynet_settings
+from .vggm import pretrained_settings as vggm_settings
 
 all_settings = [
     fbresnet_settings,
@@ -28,7 +29,8 @@ all_settings = [
     senet_settings,
     cafferesnet_settings,
     pnasnet_settings,
-    polynet_settings
+    polynet_settings,
+    vggm_settings
 ]
 
 model_names = []
