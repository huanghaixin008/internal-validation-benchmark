diff --git a/eval_voc.py b/eval_voc.py
index f62d2c8..b632310 100644
--- a/eval_voc.py
+++ b/eval_voc.py
@@ -37,7 +37,7 @@ parser.add_argument('-v', '--version', default='yolo_v2',
 parser.add_argument('-d', '--dataset', default='VOC',
                     help='VOC or COCO dataset')
 parser.add_argument('--trained_model', type=str,
-                    default='weights_yolo_v2/yolo_v2_72.2.pth', 
+                    default='weights/yolo_v2_250epoch_77.1_78.1.pth', 
                     help='Trained state_dict file path to open')
 parser.add_argument('--save_folder', default='eval/', type=str,
                     help='File path to save results')
@@ -51,24 +51,44 @@ parser.add_argument('--voc_root', default=VOC_ROOT,
                     help='Location of VOC root directory')
 parser.add_argument('--cleanup', default=True, type=str2bool,
                     help='Cleanup and remove results files following eval')
+parser.add_argument('--ipex', action='store_true', default=False,
+                    help='Use ipex')
+# parser.add_argument('--jit', action='store_true', default=False,
+#                     help='Use jit script')
+parser.add_argument('--precision', default='float32',
+                    help='precision, "float32" or "bfloat16"')
+parser.add_argument('--max_iters', default=500, type=int, 
+                    help='max number to run.')
+parser.add_argument('--warmup', default=10, type=int, 
+                    help='warmup number.')
 
 args = parser.parse_args()
+print(args)
 
 if not os.path.exists(args.save_folder):
     os.mkdir(args.save_folder)
 
-if torch.cuda.is_available():
-    if args.cuda:
+if args.cuda:
+    if torch.cuda.is_available():
         torch.set_default_tensor_type('torch.cuda.FloatTensor')
         cudnn.benchmark = True
         device = torch.device("cuda")
-    if not args.cuda:
+    else:
         print("WARNING: It looks like you have a CUDA device, but aren't using \
               CUDA.  Run with --cuda for optimal eval speed.")
         torch.set_default_tensor_type('torch.FloatTensor')
         device = torch.device("cpu")
+elif args.ipex:
+    import intel_pytorch_extension as ipex
+    print("Running with IPEX...")
+    if args.precision == 'bfloat16':
+        # Automatically mix precision
+        ipex.enable_auto_mixed_precision(mixed_dtype=torch.bfloat16)
+        print("Running with bfloat16...")
+    device = ipex.DEVICE
 else:
     torch.set_default_tensor_type('torch.FloatTensor')
+    device = torch.device("cpu")
 
 YEAR = '2007'
 devkit_path = args.voc_root + 'VOC' + YEAR
@@ -142,7 +162,8 @@ def get_output_dir(name, phase):
 def get_voc_results_file_template(image_set, cls):
     # VOCdevkit/VOC2007/results/det_test_aeroplane.txt
     filename = 'det_' + image_set + '_%s.txt' % (cls)
-    filedir = os.path.join(devkit_path, 'results')
+    # filedir = os.path.join(devkit_path, 'results')
+    filedir = 'results'
     if not os.path.exists(filedir):
         os.makedirs(filedir)
     path = os.path.join(filedir, filename)
@@ -155,6 +176,8 @@ def write_voc_results_file(all_boxes, dataset):
         filename = get_voc_results_file_template(set_type, cls)
         with open(filename, 'wt') as f:
             for im_ind, index in enumerate(dataset.ids):
+                if im_ind >= len(all_boxes[cls_ind]):
+                    break
                 dets = all_boxes[cls_ind][im_ind]
                 if dets == []:
                     continue
@@ -167,7 +190,8 @@ def write_voc_results_file(all_boxes, dataset):
 
 
 def do_python_eval(output_dir='output', use_07=True):
-    cachedir = os.path.join(devkit_path, 'annotations_cache')
+    # cachedir = os.path.join(devkit_path, 'annotations_cache')
+    cachedir = os.path.join('results', 'annotations_cache')
     aps = []
     # The PASCAL VOC metric changed in 2010
     use_07_metric = use_07
@@ -346,6 +370,8 @@ def voc_eval(detpath,
 
 def test_net(net, dataset, device, top_k):
     num_images = len(dataset)
+    if args.max_iters > 0 and (args.max_iters + args.warmup) < num_images:
+        num_images = args.max_iters + args.warmup
     # all detections are collected into:
     #    all_boxes[cls][image] = N x 5 array of detections in
     #    (x1, y1, x2, y2, score)
@@ -383,6 +409,9 @@ def test_net(net, dataset, device, top_k):
         print('im_detect: {:d}/{:d} {:.3f}s'.format(i + 1,
                                                     num_images, detect_time))
 
+    print('Throughput:{:.3f} samples/s'.format(1 / _t['im_detect'].average_time))
+    print('Latency: {:.3f} ms'.format(_t['im_detect'].average_time * 1000))
+
     with open(det_file, 'wb') as f:
         pickle.dump(all_boxes, f, pickle.HIGHEST_PROTOCOL)
 
@@ -402,23 +431,23 @@ if __name__ == '__main__':
     if args.version == 'yolo_v2':
         from models.yolo_v2 import myYOLOv2
         net = myYOLOv2(device, input_size=cfg['min_dim'], num_classes=num_classes, anchor_size=config.ANCHOR_SIZE)
-    
     elif args.version == 'yolo_v3':
         from models.yolo_v3 import myYOLOv3
         net = myYOLOv3(device, input_size=cfg['min_dim'], num_classes=num_classes, anchor_size=config.MULTI_ANCHOR_SIZE)
-    
     elif args.version == 'slim_yolo_v2':
         from models.slim_yolo_v2 import SlimYOLOv2    
         net = SlimYOLOv2(device, input_size=cfg['min_dim'], num_classes=num_classes, anchor_size=config.ANCHOR_SIZE)
         print('Let us eval slim-yolo-v2 on the VOC0712 dataset ......')
-
     elif args.version == 'tiny_yolo_v3':
         from models.tiny_yolo_v3 import YOLOv3tiny
         net = YOLOv3tiny(device, input_size=cfg['min_dim'], num_classes=num_classes, anchor_size=config.TINY_MULTI_ANCHOR_SIZE)
         print('Let us eval tiny-yolo-v3 on the VOC0712 dataset ......')
 
     # load net
-    net.load_state_dict(torch.load(args.trained_model, map_location='cuda'))
+    if args.cuda:
+        net.load_state_dict(torch.load(args.trained_model, map_location='cuda'))
+    else:
+        net.load_state_dict(torch.load(args.trained_model, map_location='cpu'))
     net.eval()
     print('Finished loading model!')
     # load data
@@ -426,7 +455,9 @@ if __name__ == '__main__':
                            BaseTransform(net.input_size, mean=(0.406, 0.456, 0.485), std=(0.225, 0.224, 0.229)),
                            VOCAnnotationTransform())
     net = net.to(device)
-    
+    # if args.jit:
+    #     net = torch.jit.script(net)
+
     # evaluation
     with torch.no_grad():
         test_net(net, dataset, device, args.top_k)
