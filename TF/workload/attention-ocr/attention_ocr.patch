diff --git a/research/attention_ocr/python/demo_inference.py b/research/attention_ocr/python/demo_inference.py
index d5fcf251..37b96941 100644
--- a/research/attention_ocr/python/demo_inference.py
+++ b/research/attention_ocr/python/demo_inference.py
@@ -1,3 +1,4 @@
+# -*- coding: utf-8 -*
 """A script to run inference on a set of image files.
 
 NOTE #1: The Attention OCR model was trained only using FSNS train dataset and
@@ -17,10 +18,13 @@ python demo_inference.py --batch_size=32 \
 """
 import numpy as np
 import PIL.Image
+import time
+import os
 
 import tensorflow as tf
 from tensorflow.python.platform import flags
 from tensorflow.python.training import monitored_session
+from tensorflow.python.client import timeline
 
 import common_flags
 import datasets
@@ -32,7 +36,11 @@ common_flags.define()
 # e.g. ./datasets/data/fsns/temp/fsns_train_%02d.png
 flags.DEFINE_string('image_path_pattern', '',
                     'A file pattern with a placeholder for the image index.')
-
+flags.DEFINE_integer('num_warmup', 50, 'Num of warmup.')
+flags.DEFINE_integer('eval_batch_size', 1, 'batch_size.')
+flags.DEFINE_integer('num_iter', 500, 'Num of total benchmark samples.')
+flags.DEFINE_integer('profile', 0, 'profiling.')
+flags.DEFINE_string('precision', 'float32', 'precision.')
 
 def get_dataset_image_size(dataset_name):
   # Ideally this info should be exposed through the dataset interface itself.
@@ -49,7 +57,8 @@ def load_images(file_pattern, batch_size, dataset_name):
   for i in range(batch_size):
     path = file_pattern % i
     print("Reading %s" % path)
-    pil_image = PIL.Image.open(tf.gfile.GFile(path, 'rb'))
+    pil_image = PIL.Image.open(tf.gfile.GFile(path,'rb'))
+    pil_image=pil_image.resize((600,150),PIL.Image.ANTIALIAS)
     images_actual_data[i, ...] = np.asarray(pil_image)
   return images_actual_data
 
@@ -71,26 +80,61 @@ def create_model(batch_size, dataset_name):
 
 
 def run(checkpoint, batch_size, dataset_name, image_path_pattern):
+  config = tf.ConfigProto()
+  config.allow_soft_placement = True
+  if FLAGS.precision == 'bfloat16':
+    try:
+      from tensorflow.core.protobuf import rewriter_config_pb2
+      config.graph_options.rewrite_options.auto_mixed_precision_mkl = rewriter_config_pb2.RewriterConfig.ON
+    except:
+      print("WARNING: Auto mixed precision got FAILED.")
+
+  run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)
+  run_metadata = tf.RunMetadata()
   images_placeholder, endpoints = create_model(batch_size,
                                                dataset_name)
-  images_data = load_images(image_path_pattern, batch_size,
-                            dataset_name)
+  #images_data = load_images(image_path_pattern, batch_size,
+  #                          dataset_name)
+  image_data = np.repeat(np.random.randn(150, 600, 3).astype('float32')[np.newaxis, :], batch_size, axis=0)
+  dummy_dataset = [image_data] * FLAGS.num_iter
+  total_time = 0
+  total_samples = 0
   session_creator = monitored_session.ChiefSessionCreator(
-    checkpoint_filename_with_path=checkpoint)
+    checkpoint_filename_with_path=checkpoint, config=config)
   with monitored_session.MonitoredSession(
       session_creator=session_creator) as sess:
-    predictions = sess.run(endpoints.predicted_text,
-                           feed_dict={images_placeholder: images_data})
-  return [pr_bytes.decode('utf-8') for pr_bytes in predictions.tolist()]
+
+    for index, data in enumerate(dummy_dataset):
+        tic = time.time()
+        if FLAGS.profile:
+            predictions = sess.run(endpoints.predicted_text,
+                               feed_dict={images_placeholder: data}, options=run_options, run_metadata=run_metadata)
+        else:
+            predictions = sess.run(endpoints.predicted_text,
+                               feed_dict={images_placeholder: data})
+        if index > FLAGS.num_warmup:
+          total_time += time.time() - tic
+          total_samples += data.shape[0]
+        if FLAGS.profile and index == FLAGS.num_iter - 1:
+          trace = timeline.Timeline(step_stats=run_metadata.step_stats)
+          trace_dir = str(os.path.dirname(os.path.realpath(__file__))) + '/timeline'
+          if not os.path.exists(trace_dir):
+            os.makedirs(trace_dir)
+          profiling_file = trace_dir + '/timeline-' + str(index + 1) + '-' + str(os.getpid()) + '.json'
+          with open(profiling_file, 'w') as trace_file:
+            trace_file.write(
+                    trace.generate_chrome_trace_format(show_memory=False))
+  print("Total samples: {}\n Throughput: {:.2f} fps".format(total_samples, total_samples/total_time))
+
+  return predictions.tolist()
 
 
 def main(_):
   print("Predicted strings:")
-  predictions = run(FLAGS.checkpoint, FLAGS.batch_size, FLAGS.dataset_name,
+  predictions = run(FLAGS.checkpoint, FLAGS.eval_batch_size, FLAGS.dataset_name,
                   FLAGS.image_path_pattern)
-  for line in predictions:
-    print(line)
-
+  # for line in predictions:
+  #   print(line)
 
 if __name__ == '__main__':
   tf.app.run()
