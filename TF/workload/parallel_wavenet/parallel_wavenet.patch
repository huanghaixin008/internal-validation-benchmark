commit 9dcb656c8f492e573cbe1d8013de3e5ded267aab
Author: mengfeil <mengfei.li@intel.com>
Date:   Mon Jun 28 21:23:34 2021 +0800

    parallel wavenet

diff --git a/eval_parallel_wavenet.py b/eval_parallel_wavenet.py
index f675cbe..b1b82bc 100644
--- a/eval_parallel_wavenet.py
+++ b/eval_parallel_wavenet.py
@@ -51,6 +51,9 @@ def generate(args):
 
     batch_size = args.batch_size
     sample_length = args.sample_length
+    num_iter = args.num_iter
+    num_warmup = args.num_warmup
+    precision = args.precision
     n = len(files)
     for start in range(0, n, batch_size):
         tf.logging.info('generating batch {:d}'.format(start // batch_size))
@@ -64,7 +67,7 @@ def generate(args):
         # use the original wave length.
         batch_data = fastgen.load_batch(batch_files, sample_length=sample_length)
         mel_data = mel_extractor.batch_melspectrogram(batch_data)
-        parallelgen.synthesis(hparams, mel_data, save_names, checkpoint_path)
+        parallelgen.synthesis(hparams, mel_data, save_names, checkpoint_path, num_iter, num_warmup, precision)
 
 
 if __name__ == '__main__':
@@ -90,5 +93,10 @@ if __name__ == '__main__':
                              "DEBUG, INFO, WARN, ERROR, or FATAL.")
     parser.add_argument("--gpu_id", default='0',
                         help="gpu device for generation.")
+    parser.add_argument("-n", "--num_iter", type=int, default=500,
+                        help="numbers of inference iteration, default is 500")
+    parser.add_argument("--num_warmup", type=int, default=10,
+                        help="numbers of warmup iteration, default is 10")
+    parser.add_argument("--precision", type=str, default='float32')
     args = parser.parse_args()
     generate(args)
diff --git a/wavenet/parallelgen.py b/wavenet/parallelgen.py
index 7eecf29..e9c1163 100644
--- a/wavenet/parallelgen.py
+++ b/wavenet/parallelgen.py
@@ -19,10 +19,16 @@ def load_parallelgen(hparams, batch_size=1, length=7680, num_mel=80):
     return fg_dict
 
 
-def synthesis(hparams, mel, save_paths, checkpoint_path):
+def synthesis(hparams, mel, save_paths, checkpoint_path, num_iter, num_warmup, precision):
     batch_size, length, num_mel = mel.shape
     session_config = tf.ConfigProto(allow_soft_placement=True)
     session_config.gpu_options.allow_growth = True
+    if precision == 'bfloat16':
+        try:
+            from tensorflow.core.protobuf import rewriter_config_pb2
+            session_config.graph_options.rewrite_options.auto_mixed_precision_mkl = rewriter_config_pb2.RewriterConfig.ON
+        except:
+            print("WARNING: Auto mixed precision got FAILED.")
     with tf.Graph().as_default(), tf.Session(config=session_config) as sess:
         fg_dict = load_parallelgen(hparams, batch_size, length, num_mel)
 
@@ -39,13 +45,32 @@ def synthesis(hparams, mel, save_paths, checkpoint_path):
             var_dict = fastgen.get_ema_shadow_dict(tf_vars)
         saver = tf.train.Saver(var_dict, reshape=True)
         saver.restore(sess, checkpoint_path)
-
-        start = time.time()
-        audio = sess.run(fg_dict['x'],
+        
+        total_time = 0.0
+        iter_done = 0
+        for i in range(num_iter):
+            if i < num_warmup:
+                _ = sess.run(fg_dict['x'],
                          feed_dict={fg_dict['mel_in']: mel})
-        cost = time.time() - start
-        wave_length = audio.shape[1] / 16000
-        tf.logging.info('Target waveform length {:.5f}, ' 
-                        'Session run consume {:.5f} secs, '
-                        'Delay {:.2f}'.format(wave_length, cost, cost / wave_length))
+                continue
+            start = time.time()
+            audio = sess.run(fg_dict['x'],
+                             feed_dict={fg_dict['mel_in']: mel})
+            cost = time.time() - start
+            wave_length = audio.shape[1] / 16000
+            
+            tf.logging.info('Iteration {:d}, '
+                            'Target waveform length {:.5f}, ' 
+                            'Session run consume {:.5f} secs, '
+                            'Delay {:.2f}'.format(iter_done, wave_length, cost, cost / wave_length))
+            
+            total_time += cost
+            iter_done += 1
+            
+        avg_time = total_time / iter_done
+        tf.logging.info('Average time {:.5f}'.format(avg_time))
+        tf.logging.info('Length {:d}'.format(length))
+        throughput = length / avg_time
+        tf.logging.info('Throughput: {:.5f}'.format(length / avg_time)) 
+                        
     fastgen.save_batch(audio, save_paths)
