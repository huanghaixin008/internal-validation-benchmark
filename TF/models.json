{
    "3DUNet":{
        "model_path":"mlp/3D-Unet/3DUNet.pb",
        "workload_path":"workload/PB"
    },
    "3d-pose-baseline":{
        "model_path":"ov/all_tf_models/human_pose_estimation/3d-pose-baseline/tf/3d-pose-baseline.pb",
        "workload_path":"workload/PB"
    },
    "ACGAN":{
        "model_path":"oob/oob_gan_models/ACGAN.pb",
        "workload_path":"workload/PB"
    },
    "ALBERT":{
        "model_path":"dpg/ALBERT/ALBERT.pb",
        "workload_path":"workload/PB"
    },
    "BEGAN":{
        "model_path":"oob/oob_gan_models/BEGAN.pb",
        "workload_path":"workload/PB"
    },
    "BERT_BASE":{
        "model_path":"mlp/BERT_BASE/BERT_BASE.pb",
        "workload_path":"workload/PB"
    },
    "BERT_LARGE":{
        "model_path":"mlp/BERT_LARGE/BERT_LARGE.pb",
        "workload_path":"workload/PB"
    },
    "CBAM":{
        "model_path":"mlp/CBAM/CBAM.pb",
        "workload_path":"workload/PB"
    },
    "CGAN":{
        "model_path":"oob/oob_gan_models/CGAN.pb",
        "workload_path":"workload/PB"
    },
    "COVID-Net":{
        "model_path":"oob/COVID-Net/COVID-Net.pb",
        "workload_path":"workload/PB"
    },
    "CRNN":{
        "model_path":"mlp/CRNN/crnn.pb",
        "workload_path":"workload/PB",
        "input_output_def":"in_model_details"
    },
    "CapsuleNet":{
        "model_path":"dpg/CapsuleNet/CapsuleNet.pb",
        "workload_path":"workload/PB",
        "input_output_def":"in_model_details"
    },
    "CenterNet":{
        "model_path":"mlp/CenterNet/CenterNet.pb",
        "workload_path":"workload/PB",
        "input_output_def":"in_model_details"
    },
    "CharCNN":{
        "model_path":"dpg/CharCNN/CharCNN.pb",
        "workload_path":"workload/PB",
        "input_output_def":"in_model_details"
    },
    "DIEN_Deep-Interest-Evolution-Network":{
        "model_path":"oob/DIEN/DIEN.pb",
        "workload_path":"workload/PB",
        "input_output_def":"in_model_details"
    },
    "DRAGAN":{
        "model_path":"oob/oob_gan_models/DRAGAN.pb",
        "workload_path":"workload/PB"
    },
    "DRAW":{
        "model_path":"dpg/DRAW/DRAW.pb",
        "workload_path":"workload/PB"
    },
    "DSSD_12":{
        "model_path":"ov/all_tf_models/PublicInHouse/object_detection/common/dssd/DSSD_12/tf/DSSD_12.pb",
        "workload_path":"workload/PB"
    },
    "DeepLab":{
        "model_path":"mlp/deeplabv3_mnv2_cityscapes_train/deeplab.pb",
        "workload_path":"workload/PB"
    },
    "DynamicMemory":{
        "model_path":"oob/checkpoint_dynamic_memory_network/DynamicMemory.pb",
        "workload_path":"workload/PB"
    },
    "EBGAN":{
        "model_path":"oob/oob_gan_models/EBGAN.pb",
        "workload_path":"workload/PB"
    },
    "EfficientDet-D0-512x512":{
        "model_path":"dpg/EfficientDet/efficientdet-d0/EfficientDet-D0-512x512.pb",
        "workload_path":"workload/PB"
    },
    "EfficientDet-D1-640x640":{
        "model_path":"dpg/EfficientDet/efficientdet-d1/EfficientDet-D1-640x640.pb",
        "workload_path":"workload/PB"
    },
    "EfficientDet-D2-768x768":{
        "model_path":"dpg/EfficientDet/efficientdet-d2/EfficientDet-D2-768x768.pb",
        "workload_path":"workload/PB"
    },
    "EfficientDet-D3-896x896":{
        "model_path":"dpg/EfficientDet/efficientdet-d3/EfficientDet-D3-896x896.pb",
        "workload_path":"workload/PB"
    },
    "EfficientDet-D4-1024x1024":{
        "model_path":"dpg/EfficientDet/efficientdet-d4/EfficientDet-D4-1024x1024.pb",
        "workload_path":"workload/PB"
    },
    "EfficientDet-D5-1280x1280":{
        "model_path":"dpg/EfficientDet/efficientdet-d5/EfficientDet-D5-1280x1280.pb",
        "workload_path":"workload/PB"
    },
    "EfficientDet-D6-1280x1280":{
        "model_path":"dpg/EfficientDet/efficientdet-d6/EfficientDet-D6-1280x1280.pb",
        "workload_path":"workload/PB"
    },
    "EfficientDet-D7-1536x1536":{
        "model_path":"dpg/EfficientDet/efficientdet-d7/EfficientDet-D7-1536x1536.pb",
        "workload_path":"workload/PB"
    },
    "EntityNet":{
        "model_path":"oob/checkpoint_entity_network2/EntityNet.pb",
        "workload_path":"workload/PB"
    },
    "Evolution_ensemble":{
        "model_path":"dpg/simple_net/Evolution_ensemble.pb",
        "workload_path":"workload/PB"
    },
    "GAN":{
        "model_path":"mlp/oob_gan_models/GAN.pb",
        "workload_path":"workload/PB"
    },
    "GraphSage":{
        "model_path":"mlp/GraphSage/GraphSage.pb",
        "workload_path":"workload/PB"
    },
    "HierAtteNet":{
        "model_path":"oob/checkpoint_hier_atten_title/text_hier_atten_title_desc_checkpoint_MHA/HierAtteNet.pb",
        "workload_path":"workload/PB"
    },
    "Hierarchical_LSTM":{
        "model_path":"dpg/Hierarchical/Hierarchical_LSTM.pb",
        "workload_path":"workload/PB",
        "input_output_def":"in_model_details"
    },
    "HugeCTR":{
        "model_path":"mlp/HugeCTR/HugeCTR.pb",
        "workload_path":"workload/PB"
    },
    "KeypointNet":{
        "model_path":"mlp/keypoint/KeypointNet.pb",
        "workload_path":"workload/PB",
        "load_graph_via_inc":"true"
    },
    "LSGAN":{
        "model_path":"mlp/oob_gan_models/LSGAN.pb",
        "workload_path":"workload/PB"
    },
    "MANN":{
        "model_path":"dpg/MANN/MANN.pb",
        "workload_path":"workload/PB",
        "input_output_def":"in_model_details"
    },
    "MiniGo":{
        "model_path":"dpg/MiniGo/MiniGo.pb",
        "workload_path":"workload/PB",
        "input_output_def":"in_model_details"
    },
    "NCF":{
        "model_path":"mlp/NCF/NCF.pb",
        "workload_path":"workload/PB"
    },
    "NCF-1B":{
        "model_path":"dpg/ncf_trained_movielens_1m/NCF-1B.pb",
        "workload_path":"workload/PB"
    },
    "NTM-One-Shot":{
        "model_path":"dpg/NTM-One-Shot/model/NTM-One-Shot.pb",
        "workload_path":"workload/PB"
    },
    "NetVLAD":{
        "model_path":"dpg/NetVLAD/NetVLAD.pb",
        "workload_path":"workload/PB"
    },
    "NeuMF":{
        "model_path":"mlp/NeuMF/NeuMF.pb",
        "workload_path":"workload/PB",
        "input_output_def":"in_model_details"
    },
    "PRNet":{
        "model_path":"ov/all_tf_models/face_reconstruction/PRNet/tf/PRNet.pb",
        "workload_path":"workload/PB",
        "input_output_def":"in_model_details"
    },
    "R-FCN":{
        "model_path":"dpg/R-FCN/rfcn_resnet101_coco_2018_01_28/R-FCN.pb",
        "workload_path":"workload/PB"
    },
    "ResNeXt_101":{
        "model_path":"dpg/ResNext_101/ResNext_101.pb",
        "workload_path":"workload/PB"
    },
    "ResNeXt_50":{
        "model_path":"dpg/ResNext_50/ResNext_50.pb",
        "workload_path":"workload/PB"
    },
    "ResNet-50_v1_5":{
        "model_path":"mlp/ResNet50_v1_5/model_dir/ResNet-50_v1.5.pb",
        "workload_path":"workload/PB"
    },
    "SSD_ResNet50_V1_FPN_640x640_RetinaNet50":{
        "model_path":"ckpt/ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03/ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03/SSD_ResNet50_V1_FPN_640x640_RetinaNet50.pb",
        "workload_path":"workload/PB"
    },
    "Seq2seqAttn":{
        "model_path":"oob/Seq2seqAttn/Seq2seqAttn.pb",
        "workload_path":"workload/PB"
    },
    "show_and_tell":{
        "model_path":"oob/show_and_tell/show_and_tell.pb",
        "workload_path":"workload/PB",
        "input_output_def":"in_model_details"
    },
    "SphereFace":{
        "model_path":"dpg/SphereFace/SphereFace.pb",
        "workload_path":"workload/PB"
    },
    "SqueezeNet":{
        "model_path":"mlp/SqueezeNet-tf/SqueezeNet.pb",
        "workload_path":"workload/PB"
    },
    "TCN":{
        "model_path":"ov/all_tf_models/PublicInHouse/sequence_modelling/tcn/tf/TCN.pb",
        "workload_path":"workload/PB"
    },
    "TextCNN":{
        "model_path":"oob/TextCNN/TextCNN.pb",
        "workload_path":"workload/PB",
        "input_output_def":"in_model_details"
    },
    "TextRCNN":{
        "model_path":"oob/TextRCNN/TextRCNN.pb",
        "workload_path":"workload/PB"
    },
    "TextRNN":{
        "model_path":"oob/TextRNN/TextRNN.pb",
        "workload_path":"workload/PB",
        "input_output_def":"in_model_details"
    },
    "Transformer-LT":{
        "model_path":"mlp/transformer_lt_official_fp32_pretrained_model/graph/Transformer-LT.pb",
        "workload_path":"workload/PB"
    },
    "U-Net":{
        "model_path":"mlp/unet/U-Net.pb",
        "workload_path":"workload/PB"
    },
    "Vnet":{
        "model_path":"mlp/vnet/vnet.pb",
        "workload_path":"workload/PB"
    },
    "WGAN":{
        "model_path":"mlp/oob_gan_models/WGAN.pb",
        "workload_path":"workload/PB"
    },
    "WGAN_GP":{
        "model_path":"oob/oob_gan_models/WGAN_GP.pb",
        "workload_path":"workload/PB"
    },
    "YOLOv4":{
        "model_path":"mlp/yolov4/YOLOv4.pb",
        "workload_path":"workload/PB"
    },
    "adv_inception_v3":{
        "model_path":"dpg/adv_inception_v3/adv_inception_v3.pb",
        "workload_path":"workload/PB",
        "inc_tune_bs":32
    },
    "aipg-vdcnn":{
        "model_path":"ov/all_tf_models/AIPG_trained/text_classification/vdcnn/agnews/tf/aipg-vdcnn.pb",
        "workload_path":"workload/PB",
        "input_output_def":"in_model_details"
    },
    "arttrack-coco-multi":{
        "model_path":"ov/all_tf_models/human_pose_estimation/arttrack/coco/tf/arttrack-coco-multi.pb",
        "workload_path":"workload/PB",
        "input_output_def":"in_model_details"
    },
    "arttrack-mpii-single":{
        "model_path":"ov/all_tf_models/human_pose_estimation/arttrack/mpii/tf/arttrack-mpii-single.pb",
        "workload_path":"workload/PB",
        "input_output_def":"in_model_details"
    },
    "ava-face-recognition-3_0_0":{
        "model_path":"ov/all_tf_models/Security/feature_extraction/ava/tf/ava-face-recognition-3.0.0.pb",
        "workload_path":"workload/PB"
    },
    "ava-person-vehicle-detection-stage2-2_0_0":{
        "model_path":"ov/all_tf_models/Security/object_detection/common/ava/stage2/tf/ava-person-vehicle-detection-stage2-2.0.0.pb",
        "workload_path":"workload/PB"
    },
    "bert-base-uncased_L-12_H-768_A-12":{
        "model_path":"ov/all_tf_models/language_representation/bert/base/uncased_L-12_H-768_A-12/tf/bert-base-uncased_L-12_H-768_A-12.pb",
        "workload_path":"workload/PB"
    },
    "context_rcnn_resnet101_snapshot_serenget":{
        "model_path":"ckpt/context_rcnn_resnet101_snapshot_serengeti_2020_06_10/context_rcnn_resnet101_snapshot_serenget.pb",
        "workload_path":"workload/PB",
        "input_output_def":"in_model_details"
    },
    "cpm-person":{
        "model_path":"ov/all_tf_models/human_pose_estimation/cpm/person/tf/cpm-person.pb",
        "workload_path":"workload/PB"
    },
    "ctpn":{
        "model_path":"ov/all_tf_models/text_detection/ctpn/tf/ctpn.pb",
        "workload_path":"workload/PB"
    },
    "darknet19":{
        "model_path":"ov/all_tf_models/PublicInHouse/classification/darknet19/darknet19.pb",
        "workload_path":"workload/PB"
    },
    "darknet53":{
        "model_path":"ov/all_tf_models/PublicInHouse/classification/darknet53/darknet53.pb",
        "workload_path":"workload/PB"
    },
    "deeplabv3":{
        "model_path":"ov/all_tf_models/semantic_segmentation/deeplab/v3/deeplabv3.pb",
        "workload_path":"workload/PB"
    },
    "deepspeech":{
        "model_path":"ov/all_tf_models/speech_to_text/deepspeech/v1/tf/deepspeech.pb",
        "workload_path":"workload/PB",
        "input_output_def":"in_model_details"
    },
    "deepvariant_wgs":{
        "model_path":"ov/all_tf_models/dna_sequencing/deepvariant/wgs/deepvariant_wgs.pb",
        "workload_path":"workload/PB",
        "input_output_def":"in_model_details"
    },
    "dense_vnet_abdominal_ct":{
        "model_path":"ov/all_tf_models/semantic_segmentation/dense_vnet/tf/dense_vnet_abdominal_ct.pb",
        "workload_path":"workload/PB",
        "input_output_def":"in_model_details"
    },
    "densenet-121":{
        "model_path":"ov/all_tf_models/classification/densenet/121/tf/densenet-121.pb",
        "workload_path":"workload/PB"
    },
    "densenet-161":{
        "model_path":"ov/all_tf_models/classification/densenet/161/tf/densenet-161.pb",
        "workload_path":"workload/PB"
    },
    "densenet-169":{
        "model_path":"ov/all_tf_models/classification/densenet/169/tf/densenet-169.pb",
        "workload_path":"workload/PB"
    },
    "dilation":{
        "model_path":"ov/Dilation/dilation.pb",
        "workload_path":"workload/PB"
    },
    "east_resnet_v1_50":{
        "model_path":"ov/all_tf_models/text_detection/east/tf/east_resnet_v1_50.pb",
        "workload_path":"workload/PB",
        "input_output_def":"in_model_details"
    },
    "efficientnet-b0":{
        "model_path":"ov/all_tf_models/classification/efficientnet/b0/tf/efficientnet-b0.pb",
        "workload_path":"workload/PB",
        "input_output_def":"in_model_details"
    },
    "efficientnet-b0_auto_aug":{
        "model_path":"ov/all_tf_models/classification/efficientnet/b0_auto_aug/tf/efficientnet-b0_auto_aug.pb",
        "workload_path":"workload/PB",
        "input_output_def":"in_model_details"
    },
    "efficientnet-b5":{
        "model_path":"ov/all_tf_models/classification/efficientnet/b5/tf/efficientnet-b5.pb",
        "workload_path":"workload/PB",
        "input_output_def":"in_model_details"
    },
    "efficientnet-b7_auto_aug":{
        "model_path":"ov/all_tf_models/classification/efficientnet/b7_auto_aug/tf/efficientnet-b7_auto_aug.pb",
        "workload_path":"workload/PB",
        "input_output_def":"in_model_details"
    },
    "ens3_adv_inception_v3":{
        "model_path":"dpg/ens3_inception_v3/ens3_adv_inception_v3.pb",
        "workload_path":"workload/PB",
        "inc_tune_bs":32
    },
    "facenet-20180408-102900":{
        "model_path":"ov/all_tf_models/face_recognition/facenet/CASIA-WebFace/tf/facenet-20180408-102900.pb",
        "workload_path":"workload/PB",
        "input_output_def":"in_model_details"
    },
    "faster_rcnn_inception_resnet_v2_atrous_coco":{
        "model_path":"ov/all_tf_models/object_detection/common/faster_rcnn/faster_rcnn_inception_resnet_v2_atrous_coco/tf/faster_rcnn_inception_resnet_v2_atrous_coco.pb",
        "workload_path":"workload/PB"
    },
    "faster_rcnn_inception_resnet_v2_atrous_lowproposals_coco":{
        "model_path":"ckpt/faster_rcnn_inception_resnet_v2_atrous_lowproposals_coco_2018_01_28/faster_rcnn_inception_resnet_v2_atrous_lowproposals_coco.pb",
        "workload_path":"workload/PB"
    },
    "faster_rcnn_inception_resnet_v2_atrous_lowproposals_oid":{
        "model_path":"mlp/faster_rcnn_inception_resnet_v2_atrous_lowproposals_oid/faster_rcnn_inception_resnet_v2_atrous_lowproposals_oid.pb",
        "workload_path":"workload/PB"
    },
    "faster_rcnn_inception_resnet_v2_atrous_oid":{
        "model_path":"mlp/faster_rcnn_inception_resnet_v2_atrous_oid/faster_rcnn_inception_resnet_v2_atrous_oid.pb",
        "workload_path":"workload/PB"
    },
    "faster_rcnn_inception_v2_coco":{
        "model_path":"ov/all_tf_models/object_detection/common/faster_rcnn/faster_rcnn_inception_v2_coco/tf/faster_rcnn_inception_v2_coco.pb",
        "workload_path":"workload/PB"
    },
    "faster_rcnn_nas_coco_2018_01_28":{
        "model_path":"ckpt/faster_rcnn_nas_coco_2018_01_28/faster_rcnn_nas_coco_2018_01_28.pb",
        "workload_path":"workload/PB"
    },
    "faster_rcnn_nas_lowproposals_coco":{
        "model_path":"ov/all_tf_models/object_detection/common/faster_rcnn/faster_rcnn_nas_lowproposals_coco/tf/faster_rcnn_nas_lowproposals_coco.pb",
        "workload_path":"workload/PB"
    },
    "faster_rcnn_resnet101_coco":{
        "model_path":"ov/all_tf_models/object_detection/common/faster_rcnn/faster_rcnn_resnet101_coco/tf/faster_rcnn_resnet101_coco.pb",
        "workload_path":"workload/PB"
    },
    "faster_rcnn_resnet101_fgvc":{
        "model_path":"ckpt/faster_rcnn_resnet101_fgvc_2018_07_19/faster_rcnn_resnet101_fgvc_2018_07_19/faster_rcnn_resnet101_fgvc.pb",
        "workload_path":"workload/PB"
    },
    "faster_rcnn_resnet101_kitti":{
        "model_path":"ckpt/faster_rcnn_resnet101_kitti_2018_01_28/faster_rcnn_resnet101_kitti_2018_01_28/faster_rcnn_resnet101_kitti.pb",
        "workload_path":"workload/PB"
    },
    "faster_rcnn_resnet101_lowproposals_coco":{
        "model_path":"ckpt/faster_rcnn_resnet101_lowproposals_coco_2018_01_28/faster_rcnn_resnet101_lowproposals_coco_2018_01_28/faster_rcnn_resnet101_lowproposals_coco.pb",
        "workload_path":"workload/PB"
    },
    "faster_rcnn_resnet101_snapshot_serengeti":{
        "model_path":"mlp/faster_rcnn_resnet101_snapshot_serengeti/faster_rcnn_resnet101_snapshot_serengeti.pb",
        "workload_path":"workload/PB"
    },
    "faster_rcnn_resnet50_coco":{
        "model_path":"ov/all_tf_models/object_detection/common/faster_rcnn/faster_rcnn_resnet50_coco/tf/faster_rcnn_resnet50_coco.pb",
        "workload_path":"workload/PB"
    },
    "faster_rcnn_resnet50_fgvc":{
        "model_path":"ckpt/faster_rcnn_resnet50_fgvc_2018_07_19/faster_rcnn_resnet50_fgvc_2018_07_19/faster_rcnn_resnet50_fgvc.pb",
        "workload_path":"workload/PB"
    },
    "faster_rcnn_resnet50_lowproposals_coco":{
        "model_path":"ov/all_tf_models/object_detection/common/faster_rcnn/faster_rcnn_resnet50_lowproposals_coco/tf/faster_rcnn_resnet50_lowproposals_coco.pb",
        "workload_path":"workload/PB"
    },
    "gmcnn-places2":{
        "model_path":"ov/all_tf_models/image_inpainting/gmcnn/tf/gmcnn-places2.pb",
        "workload_path":"workload/PB"
    },
    "googlenet-v1":{
        "model_path":"ov/all_tf_models/classification/googlenet/v1/tf/googlenet-v1.pb",
        "workload_path":"workload/PB"
    },
    "googlenet-v2":{
        "model_path":"ov/all_tf_models/classification/googlenet/v2/tf/googlenet-v2.pb",
        "workload_path":"workload/PB"
    },
    "googlenet-v3":{
        "model_path":"ov/all_tf_models/classification/googlenet/v3/tf/googlenet-v3.pb",
        "workload_path":"workload/PB"
    },
    "googlenet-v4":{
        "model_path":"ov/all_tf_models/classification/googlenet/v4/tf/googlenet-v4.pb",
        "workload_path":"workload/PB"
    },
    "handwritten-score-recognition-0003":{
        "model_path":"ov/all_tf_models/Retail/handwritten-score-recognition/0003/tf/handwritten-score-recognition-0003.pb",
        "workload_path":"workload/PB",
        "input_output_def":"in_model_details"
    },
    "i3d-flow":{
        "model_path":"ov/all_tf_models/action_recognition/i3d/flow/tf/i3d-flow.pb",
        "workload_path":"workload/PB"
    },
    "i3d-rgb":{
        "model_path":"ov/all_tf_models/action_recognition/i3d/rgb/tf/i3d-rgb.pb",
        "workload_path":"workload/PB"
    },
    "icnet-camvid-ava-0001":{
        "model_path":"ov/all_tf_models/PublicCompressed/semantic_segmentation/icnet-camvid-tf-ws00/icnet-camvid-ava-0001.pb",
        "workload_path":"workload/PB",
        "inc_tune_bs":16
    },
    "icnet-camvid-ava-sparse-30-0001":{
        "model_path":"ov/all_tf_models/PublicCompressed/semantic_segmentation/icnet-camvid-tf-ws30/icnet-camvid-ava-sparse-30-0001.pb",
        "workload_path":"workload/PB",
        "inc_tune_bs":16
    },
    "icnet-camvid-ava-sparse-60-0001":{
        "model_path":"ov/all_tf_models/PublicCompressed/semantic_segmentation/icnet-camvid-tf-ws60/icnet-camvid-ava-sparse-60-0001.pb",
        "workload_path":"workload/PB",
        "inc_tune_bs":16
    },
    "icv-emotions-recognition-0002":{
        "model_path":"ov/all_tf_models/Retail/object_attributes/emotions_recognition/0002/tf/icv-emotions-recognition-0002.pb",
        "workload_path":"workload/PB"
    },
    "image-retrieval-0001":{
        "model_path":"ov/all_tf_models/classification/image-retrieval-0001/image-retrieval-0001.pb",
        "workload_path":"workload/PB"
    },
    "inception-resnet-v2":{
        "model_path":"ov/all_tf_models/classification/inception-resnet/v2/tf/inception-resnet-v2.pb",
        "workload_path":"workload/PB"
    },
    "inceptionv2_ssd":{
        "model_path":"ov/all_tf_models/object_detection/common/ssd_inceptionv2/tf/inceptionv2_ssd.pb",
        "workload_path":"workload/PB"
    },
    "infoGAN":{
        "model_path":"oob/oob_gan_models/infoGAN.pb",
        "workload_path":"workload/PB"
    },
    "intel-labs-nonlocal-dehazing":{
        "model_path":"ov/all_tf_models/IntelLabs/FastImageProcessing/NonlocalDehazing/intel-labs-nonlocal-dehazing.pb",
        "workload_path":"workload/PB"
    },
    "key-value-memory-networks":{
        "model_path":"dpg/key-value-memory-networks/key-value-memory-networks.pb",
        "workload_path":"workload/PB"
    },
    "learning-to-see-in-the-dark-fuji":{
        "model_path":"ov/all_tf_models/IntelLabs/LearningToSeeInTheDark/Fuji/learning-to-see-in-the-dark-fuji.pb",
        "workload_path":"workload/PB"
    },
    "learning-to-see-in-the-dark-sony":{
        "model_path":"ov/all_tf_models/IntelLabs/LearningToSeeInTheDark/Sony/learning-to-see-in-the-dark-sony.pb",
        "workload_path":"workload/PB"
    },
    "license-plate-recognition-barrier-0007":{
        "model_path":"ov/all_tf_models/optical_character_recognition/license_plate_recognition/tf/license-plate-recognition-barrier-0007.pb",
        "workload_path":"workload/PB",
        "input_output_def":"in_model_details"
    },
    "mask_rcnn_inception_resnet_v2_atrous_coco":{
        "model_path":"ov/all_tf_models/instance_segmentation/mask_rcnn/mask_rcnn_inception_resnet_v2_atrous_coco/tf/mask_rcnn_inception_resnet_v2_atrous_coco.pb",
        "workload_path":"workload/PB"
    },
    "mask_rcnn_inception_v2_coco":{
        "model_path":"ov/all_tf_models/instance_segmentation/mask_rcnn/mask_rcnn_inception_v2_coco/tf/mask_rcnn_inception_v2_coco.pb",
        "workload_path":"workload/PB"
    },
    "mask_rcnn_resnet101_atrous_coco":{
        "model_path":"ov/all_tf_models/instance_segmentation/mask_rcnn/mask_rcnn_resnet101_atrous_coco/tf/mask_rcnn_resnet101_atrous_coco.pb",
        "workload_path":"workload/PB"
    },
    "mask_rcnn_resnet50_atrous_coco":{
        "model_path":"ov/all_tf_models/instance_segmentation/mask_rcnn/mask_rcnn_resnet50_atrous_coco/tf/mask_rcnn_resnet50_atrous_coco.pb",
        "workload_path":"workload/PB"
    },
    "nasnet-a-large-331":{
        "model_path":"ov/all_tf_models/classification/nasnet/large/tf/nasnet-a-large-331.pb",
        "workload_path":"workload/PB"
    },
    "nasnet-a-mobile-224":{
        "model_path":"ov/all_tf_models/classification/nasnet/mobile/tf/nasnet-a-mobile-224.pb",
        "workload_path":"workload/PB"
    },
    "openpose-pose":{
        "model_path":"ov/all_tf_models/human_pose_estimation/openpose/pose/tf/openpose-pose.pb",
        "workload_path":"workload/PB"
    },
    "optical_character_recognition-text_recognition-tf":{
        "model_path":"ov/all_tf_models/optical_character_recognition/text_recognition/tf/optical_character_recognition-text_recognition-tf.pb",
        "workload_path":"workload/PB",
        "input_output_def":"in_model_details"
    },
    "person-vehicle-bike-detection-crossroad-yolov3-1020":{
        "model_path":"ov/all_tf_models/Security/object_detection/crossroad/1020/tf/person-vehicle-bike-detection-crossroad-yolov3-1020.pb",
        "workload_path":"workload/PB"
    },
    "person-vehicle-bike-detection-crossroad-yolov3-1024":{
        "model_path":"ov/all_tf_models/Security/object_detection/crossroad/1024/tf/person-vehicle-bike-detection-crossroad-yolov3-1024.pb",
        "workload_path":"workload/PB"
    },
    "pose-ae-multiperson":{
        "model_path":"ov/all_tf_models/human_pose_estimation/pose-ae/multiperson/tf/pose-ae-multiperson.pb",
        "workload_path":"workload/PB",
        "input_output_def":"in_model_details",
        "load_graph_via_inc":"true"
    },
    "pose-ae-refinement":{
        "model_path":"ov/all_tf_models/human_pose_estimation/pose-ae/refinement/tf/pose-ae-refinement.pb",
        "workload_path":"workload/PB",
        "input_output_def":"in_model_details",
        "load_graph_via_inc":"true"
    },
    "resnet-101":{
        "model_path":"ov/all_tf_models/classification/resnet/v1/101/tf/resnet-101.pb",
        "workload_path":"workload/PB"
    },
    "resnet-152":{
        "model_path":"ov/all_tf_models/classification/resnet/v1/152/tf/resnet-152.pb",
        "workload_path":"workload/PB"
    },
    "resnet-50":{
        "model_path":"ov/all_tf_models/classification/resnet/v1/50/tf/official/resnet-50.pb",
        "workload_path":"workload/PB"
    },
    "resnet-v2-101":{
        "model_path":"ov/all_tf_models/classification/resnet/v2/101/tf/resnet-v2-101.pb",
        "workload_path":"workload/PB"
    },
    "resnet-v2-152":{
        "model_path":"ov/all_tf_models/classification/resnet/v2/152/tf/resnet-v2-152.pb",
        "workload_path":"workload/PB"
    },
    "resnet-v2-50":{
        "model_path":"ov/all_tf_models/classification/resnet/v2/50/tf/224x224/resnet-v2-50.pb",
        "workload_path":"workload/PB"
    },
    "resnet_v2_200":{
        "model_path":"dpg/Resnet_v2_200/resnet_v2_200.pb",
        "workload_path":"workload/PB",
        "input_output_def":"in_model_details"
    },
    "retinanet":{
        "model_path":"ov/all_tf_models/object_detection/common/retinanet/tf/retinanet.pb",
        "workload_path":"workload/PB"
    },
    "rfcn-resnet101-coco":{
        "model_path":"ov/all_tf_models/object_detection/common/rfcn/rfcn_resnet101_coco/tf/rfcn-resnet101-coco.pb",
        "workload_path":"workload/PB"
    },
    "rmnet_ssd":{
        "model_path":"ov/all_tf_models/Retail/action_detection/pedestrian/rmnet_ssd/0028_tf/tf/rmnet_ssd.pb",
        "workload_path":"workload/PB"
    },
    "squeezenet1_1":{
        "model_path":"ov/all_tf_models/classification/squeezenet/1.1/tf/squeezenet1_1.pb",
        "workload_path":"workload/PB"
    },
    "srgan":{
        "model_path":"ov/all_tf_models/image_processing/srgan/tf/srgan.pb",
        "workload_path":"workload/PB"
    },
    "ssd_inception_v2_coco":{
        "model_path":"ckpt/ssd_inception_v2_coco_2018_01_28/ssd_inception_v2_coco_2018_01_28/ssd_inception_v2_coco.pb",
        "workload_path":"workload/PB"
    },
    "ssd_mobilenet_v1_0_75_depth_300x300_coco":{
        "model_path":"mlp/ssd_mobilenet_v1_0.75_depth_300x300_coco/ssd_mobilenet_v1_0.75_depth_300x300_coco.pb",
        "workload_path":"workload/PB"
    },
    "ssd_mobilenet_v1_ppn_shared_box_predictor_300x300_coco":{
        "model_path":"mlp/ssd_mobilenet_v1_ppn_shared_box_predictor_300x300_coco/ssd_mobilenet_v1_ppn_shared_box_predictor_300x300_coco.pb",
        "workload_path":"workload/PB"
    },
    "ssd_resnet34_1200x1200":{
        "model_path":"mlp/ssd_resnet34_model/ssd_resnet34_1200x1200.pb",
        "workload_path":"workload/PB"
    },
    "ssd_resnet34_300x300":{
        "model_path":"ckpt/ssd-resnet34_300x300/ssd_resnet34_300x300.pb",
        "workload_path":"workload/PB"
    },
    "ssd_resnet34_fp32_1200x1200_pretrained_model":{
        "model_path":"dpg/SSD-ResNet34_1200x1200/ssd_resnet34_fp32_1200x1200_pretrained_model.pb",
        "workload_path":"workload/PB"
    },
    "ssd_resnet50_v1_fpn_coco":{
        "model_path":"ov/all_tf_models/object_detection/common/ssd_resnet50/ssd_resnet50_v1_fpn_coco/tf/ssd_resnet50_v1_fpn_coco.pb",
        "workload_path":"workload/PB"
    },
    "ssd_resnet_101_fpn_oidv4":{
        "model_path":"ckpt/ssd_resnet101_v1_fpn/ssd_resnet_101_fpn_oidv4.pb",
        "workload_path":"workload/PB"
    },
    "text-recognition-0012":{
        "model_path":"ov/all_tf_models/Retail/text_recognition/bilstm_crnn_bilstm_decoder/0012/tf/text-recognition-0012.pb",
        "workload_path":"workload/PB",
        "input_output_def":"in_model_details"
    },
    "tiny_yolo_v1":{
        "model_path":"ov/all_tf_models/PublicInHouse/object_detection/common/yolo/v1_tiny/tf/tiny_yolo_v1.pb",
        "workload_path":"workload/PB"
    },
    "tiny_yolo_v2":{
        "model_path":"ov/all_tf_models/PublicInHouse/object_detection/common/yolo/v2_tiny/tf/tiny_yolo_v2.pb",
        "workload_path":"workload/PB"
    },
    "unet-3d-isensee_2017":{
        "model_path":"ov/all_tf_models/PublicInHouse/volumetric_segmentation/unet/3d/isensee_2017/tf/unet-3d-isensee_2017.pb",
        "workload_path":"workload/PB"
    },
    "unet-3d-origin":{
        "model_path":"ov/all_tf_models/PublicInHouse/volumetric_segmentation/unet/3d/origin/tf/unet-3d-origin.pb",
        "workload_path":"workload/PB"
    },
    "vehicle-attributes-barrier-0103":{
        "model_path":"ov/all_tf_models/object_attributes/vehicle_attributes/tf/vehicle-attributes-barrier-0103.pb",
        "workload_path":"workload/PB"
    },
    "vehicle-license-plate-detection-barrier-0106":{
        "model_path":"ov/vehicle-license-plate-detection-barrier-0106/vehicle-license-plate-detection-barrier-0106.pb",
        "workload_path":"workload/PB"
    },
    "vehicle-license-plate-detection-barrier-0123":{
        "model_path":"ov/all_tf_models/object_detection/barrier/tf/0123/vehicle-license-plate-detection-barrier-0123.pb",
        "workload_path":"workload/PB"
    },
    "vgg16":{
        "model_path":"ov/all_tf_models/classification/vgg/16/tf/vgg16.pb",
        "workload_path":"workload/PB"
    },
    "vgg19":{
        "model_path":"ov/all_tf_models/classification/vgg/19/tf/vgg19.pb",
        "workload_path":"workload/PB"
    },
    "vggvox":{
        "model_path":"ov/all_tf_models/voice_recognition/vggvox/vggvox.pb",
        "workload_path":"workload/PB",
        "input_output_def":"in_model_details"
    },
    "wavenet":{
        "model_path":"dpg/wavenet/wavenet.pb",
        "workload_path":"workload/PB"
    },
    "wide_deep":{
        "model_path":"dpg/wide_deep/wide_deep.pb",
        "workload_path":"workload/PB",
        "input_output_def":"in_model_details"
    },
    "yolo-v2":{
        "model_path":"ov/all_tf_models/object_detection/yolo/yolo_v2/tf/yolo-v2.pb",
        "workload_path":"workload/PB"
    },
    "yolo-v2-ava-sparse-35-0001":{
        "model_path":"ov/all_tf_models/PublicCompressed/detection/YOLOv2/fp32_sparsity35/yolo-v2-ava-sparse-35-0001.pb",
        "workload_path":"workload/PB"
    },
    "yolo-v2-ava-sparse-70-0001":{
        "model_path":"ov/all_tf_models/PublicCompressed/detection/YOLOv2/fp32_sparsity70/yolo-v2-ava-sparse-70-0001.pb",
        "workload_path":"workload/PB"
    },
    "yolo-v2-tiny-ava-0001":{
        "model_path":"ov/all_tf_models/PublicCompressed/detection/tinyYOLOv2/fp32_sparsity00/yolo-v2-tiny-ava-0001.pb",
        "workload_path":"workload/PB"
    },
    "yolo-v2-tiny-ava-sparse-30-0001":{
        "model_path":"ov/all_tf_models/PublicCompressed/detection/tinyYOLOv2/fp32_sparsity30/yolo-v2-tiny-ava-sparse-30-0001.pb",
        "workload_path":"workload/PB"
    },
    "yolo-v2-tiny-ava-sparse-60-0001":{
        "model_path":"ov/all_tf_models/PublicCompressed/detection/tinyYOLOv2/fp32_sparsity60/yolo-v2-tiny-ava-sparse-60-0001.pb",
        "workload_path":"workload/PB"
    },
    "yolo-v2-tiny-vehicle-detection-0001":{
        "model_path":"ov/all_tf_models/Security/object_detection/barrier/yolo/yolo-v2-tiny-vehicle-detection-0001/tf/yolo-v2-tiny-vehicle-detection-0001.pb",
        "workload_path":"workload/PB"
    },
    "yolo-v3":{
        "model_path":"ov/all_tf_models/object_detection/yolo/yolo_v3/tf/yolo-v3.pb",
        "workload_path":"workload/PB"
    },
    "yolo-v3-tiny":{
        "model_path":"ov/all_tf_models/object_detection/yolo/yolo_v3/yolo-v3-tiny/yolo-v3-tiny-tf/yolo-v3-tiny.pb",
        "workload_path":"workload/PB",
        "input_output_def":"in_model_details"
    },
    "faster_rcnn_resnet101_ava_v2_1":{
        "model_path":"ckpt/faster_rcnn_resnet101_ava_v2/faster_rcnn_resnet101_ava_v2.1_2018_04_30/frozen_inference_graph.pb",
        "workload_path":"workload/PB"
    },
    "DCGAN":{
        "model_path":"mlp/dcgan/DCGAN.pb",
        "workload_path":"workload/PB"
    },
    "Caser":{
        "model_path":"ckpt/DeepRec/Caser/Caser.pb",
        "workload_path":"workload/PB"
    },


    "AttRec":{
        "model_path":"AttRec/",
        "workload_path":"workload/AttRec"
    },
    "Attention_OCR":{
        "model_path":"mlp/attention_ocr/",
        "workload_path":"workload/attention-ocr"
    },
    "DETR":{
        "model_path":"dpg/DETR/weights/detr/",
        "workload_path":"workload/DETR"
    },
    "DLRM":{
        "model_path":"dpg/DLRM/",
        "workload_path":"workload/DLRM-tf"
    },
    "Deep_Speech_2":{
        "model_path":"dpg/Deep_Speech2/dataset",
        "workload_path":"workload/Deep_Speech2"
    },
    "Elmo":{
        "model_path":"dpg/elmo/",
        "workload_path":"workload/elmo"
    },
    "GPT2":{
        "model_path":"dpg/GPT-2/gpt-2/models/",
        "workload_path":"workload/GPT-2"
    },
    "VAE-CF":{
        "model_path":"VAE-CF/data/",
        "workload_path":"workload/VAE-CF"
    },
    "WD":{
        "model_path":"mlp/WD/wide_deep_saved_models",
        "workload_path":"workload/WD"
    },
    "adversarial_text":{
        "model_path":"mlp/adversarial_text/",
        "workload_path":"workload/adversarial_text"
    },
    "Time_series_LSTM":{
        "model_path":"time_series_LSTM/model/",
        "workload_path":"workload/time_series_LSTM"
    },
    "PNASNet-5":{
        "model_path":"dpg/PNASNet-5/Generated_LPOT_OOB_Model/",
        "workload_path":"workload/PB",
        "output_name":"final_layer/FC/BiasAdd",
        "load_graph_via_inc":"true"
    },
    "Parallel_WaveNet":{
        "model_path":"dpg/Parallel_WaveNet/Generated_LPOT_OOB_Model/",
        "workload_path":"workload/PB",
        "output_name":"truediv_1",
        "load_graph_via_inc":"true"
    },
    "ResNest101":{
        "model_path":"oob/ResNest/ResNest101",
        "workload_path":"workload/PB",
        "load_graph_via_inc":"true"
    },
    "ResNest50":{
        "model_path":"oob/ResNest/ResNest50",
        "workload_path":"workload/PB",
        "load_graph_via_inc":"true"
    },
    "ResNest50-3D":{
        "model_path":"oob/ResNest/ResNest50-3D",
        "workload_path":"workload/PB",
        "load_graph_via_inc":"true"
    },
    "Unet":{
        "model_path":"oob/Unet/Unet-Generated_LPOT_OOB_Model/Unet/",
        "workload_path":"workload/PB",
        "load_graph_via_inc":"true"
    },
    "centernet_hg104":{
        "model_path":"ckpt/centernet_hg104_1024x1024_coco17/saved_model/",
        "workload_path":"workload/PB",
        "load_graph_via_inc":"true"
    },


    "lz-3dunet":{
        "model_path":"intel-models/3dunet/",
        "workload_path":"workload/lz-3dunet"
    },
    "lz-bert-large":{
        "model_path":"intel-models/bert_large/",
        "workload_path":"workload/lz-bert-large"
    },
    "lz-dien":{
        "model_path":"intel-models/dien/",
        "workload_path":"workload/lz-dien"
    },
    "lz-mobilenetv1":{
        "model_path":"intel-models/mobilenetv1/",
        "workload_path":"workload/lz-mobilenetv1"
    },
    "lz-resnet50-v1.5":{
        "model_path":"intel-models/resnet50v1_5/",
        "workload_path":"workload/lz-resnet50-v1.5"
    },
    "lz-ssd-resnet34":{
        "model_path":"intel-models/ssd_resnet34/",
        "workload_path":"workload/lz-ssd-resnet34"
    },
    "lz-ssd-mobilenetv1":{
        "model_path":"intel-models/ssd_mobilenetv1/",
        "workload_path":"workload/lz-ssd-mobilenetv1"
    },
    "lz-transformer-lt":{
        "model_path":"intel-models/transformer_mlperf/",
        "workload_path":"workload/lz-transformer-lt"
    },
    "lz-wide-deep":{
        "model_path":"intel-models/wide_deep/",
        "workload_path":"workload/lz-wide-deep"
    },


    "keras":{
        "model_path":"examples",
        "workload_path":"workload/keras"
    },
    "keras-antirectifier":{
        "model_path":"examples/keras_recipes",
        "workload_path":"workload/keras",
        "execute_file":"antirectifier.py"
    },
    "keras-autoencoder":{
        "model_path":"examples/vision",
        "workload_path":"workload/keras",
        "execute_file":"autoencoder.py"
    },
    "keras-collaborative_filtering_movielens":{
        "model_path":"examples/structured_data",
        "workload_path":"workload/keras",
        "execute_file":"collaborative_filtering_movielens.py"
    },
    "keras-ddpg_pendulum":{
        "model_path":"examples/rl",
        "workload_path":"workload/keras",
        "execute_file":"ddpg_pendulum.py"
    },
    "keras-deep_neural_decision_forests":{
        "model_path":"examples/structured_data",
        "workload_path":"workload/keras",
        "execute_file":"deep_neural_decision_forests.py"
    },
    "keras-image_classification_with_vision_transformer":{
        "model_path":"examples/vision",
        "workload_path":"workload/keras",
        "execute_file":"image_classification_with_vision_transformer.py"
    },
    "keras-keypoint_detection":{
        "model_path":"examples/vision",
        "workload_path":"workload/keras",
        "execute_file":"keypoint_detection.py"
    },
    "keras-mnist_convnet":{
        "model_path":"examples/vision",
        "workload_path":"workload/keras",
        "execute_file":"mnist_convnet.py"
    },
    "keras-neural_style_transfer":{
        "model_path":"examples/generative",
        "workload_path":"workload/keras",
        "execute_file":"neural_style_transfer.py"
    },
    "keras-node2vec_movielens":{
        "model_path":"examples/graph",
        "workload_path":"workload/keras",
        "execute_file":"node2vec_movielens.py"
    },
    "keras-quasi_svm":{
        "model_path":"examples/keras_recipes",
        "workload_path":"workload/keras",
        "execute_file":"quasi_svm.py"
    },
    "keras-semantic_similarity_with_bert":{
        "model_path":"examples/nlp",
        "workload_path":"workload/keras",
        "execute_file":"semantic_similarity_with_bert.py"
    },
    "keras-speaker_recognition_using_cnn":{
        "model_path":"examples/audio",
        "workload_path":"workload/keras",
        "execute_file":"speaker_recognition_using_cnn.py"
    },
    "keras-timeseries_anomaly_detection":{
        "model_path":"examples/timeseries",
        "workload_path":"workload/keras",
        "execute_file":"timeseries_anomaly_detection.py"
    },
    "keras-timeseries_classification_from_scratch":{
        "model_path":"examples/timeseries",
        "workload_path":"workload/keras",
        "execute_file":"timeseries_classification_from_scratch.py"
    },
    "keras-bayesian_neural_networks":{
        "model_path":"examples/keras_recipes",
        "workload_path":"workload/keras",
        "execute_file":"bayesian_neural_networks.py"
    },
    "keras-deep_q_network_breakout":{
        "model_path":"examples/rl",
        "workload_path":"workload/keras",
        "execute_file":"deep_q_network_breakout.py"
    },
    "keras-cyclegan":{
        "model_path":"examples/generative",
        "workload_path":"workload/keras",
        "execute_file":"cyclegan.py"
    },
    "keras-transformer_asr":{
        "model_path":"examples/audio",
        "workload_path":"workload/keras",
        "execute_file":"transformer_asr.py"
    },
    "keras-text_extraction_with_bert":{
        "model_path":"examples/nlp",
        "workload_path":"workload/keras",
        "execute_file":"text_extraction_with_bert.py"
    },
    "keras-retinanet":{
        "model_path":"examples/vision",
        "workload_path":"workload/keras",
        "execute_file":"retinanet.py"
    },
    "keras-lstm_seq2seq":{
        "model_path":"examples/nlp",
        "workload_path":"workload/keras",
        "execute_file":"lstm_seq2seq.py"
    },
    "keras-masked_language_modeling":{
        "model_path":"examples/nlp",
        "workload_path":"workload/keras",
        "execute_file":"masked_language_modeling.py"
    },
    "keras-nl_image_search":{
        "model_path":"examples/vision",
        "workload_path":"workload/keras",
        "execute_file":"nl_image_search.py"
    },
    "keras-movielens_recommendations_transformers":{
        "model_path":"examples/structured_data",
        "workload_path":"workload/keras",
        "execute_file":"movielens_recommendations_transformers.py"
    },

    "savedmodel-antirectifier":{
        "model_path":"keras-io/saved_model/antirectifier-savedmodel",
        "workload_path":"workload/PB",
        "execute_file":"antirectifier.py",
        "load_graph_via_inc":"true"
    },
    "savedmodel-autoencoder":{
        "model_path":"keras-io/saved_model/autoencoder-savedmodel",
        "workload_path":"workload/PB",
        "execute_file":"autoencoder.py",
        "load_graph_via_inc":"true"
    },
    "savedmodel-collaborative_filtering_movielens":{
        "model_path":"keras-io/saved_model/collaborative_filtering_movielens-savedmodel",
        "workload_path":"workload/PB",
        "execute_file":"collaborative_filtering_movielens.py",
        "load_graph_via_inc":"true"
    },
    "savedmodel-ddpg_pendulum":{
        "model_path":"keras-io/saved_model/ddpg_pendulum-savedmodel",
        "workload_path":"workload/PB",
        "execute_file":"ddpg_pendulum.py",
        "load_graph_via_inc":"true"
    },
    "savedmodel-deep_neural_decision_forests":{
        "model_path":"keras-io/saved_model/deep_neural_decision_forests-savedmodel",
        "workload_path":"workload/PB",
        "execute_file":"deep_neural_decision_forests.py",
        "load_graph_via_inc":"true"
    },
    "savedmodel-image_classification_with_vision_transformer":{
        "model_path":"keras-io/saved_model/image_classification_with_vision_transformer-savedmodel",
        "workload_path":"workload/PB",
        "execute_file":"image_classification_with_vision_transformer.py",
        "load_graph_via_inc":"true"
    },
    "savedmodel-keypoint_detection":{
        "model_path":"keras-io/saved_model/keypoint_detection-savedmodel",
        "workload_path":"workload/PB",
        "execute_file":"keypoint_detection.py",
        "load_graph_via_inc":"true"
    },
    "savedmodel-mnist_convnet":{
        "model_path":"keras-io/saved_model/mnist_convnet-savedmodel",
        "workload_path":"workload/PB",
        "execute_file":"mnist_convnet.py",
        "load_graph_via_inc":"true"
    },
    "savedmodel-neural_style_transfer":{
        "model_path":"keras-io/saved_model/neural_style_transfer-savedmodel",
        "workload_path":"workload/PB",
        "execute_file":"neural_style_transfer.py",
        "load_graph_via_inc":"true"
    },
    "savedmodel-node2vec_movielens":{
        "model_path":"keras-io/saved_model/node2vec_movielens-savedmodel",
        "workload_path":"workload/PB",
        "execute_file":"node2vec_movielens.py",
        "load_graph_via_inc":"true"
    },
    "savedmodel-quasi_svm":{
        "model_path":"keras-io/saved_model/quasi_svm-savedmodel",
        "workload_path":"workload/PB",
        "execute_file":"quasi_svm.py",
        "load_graph_via_inc":"true"
    },
    "savedmodel-semantic_similarity_with_bert":{
        "model_path":"keras-io/saved_model/semantic_similarity_with_bert-savedmodel",
        "workload_path":"workload/PB",
        "execute_file":"semantic_similarity_with_bert.py",
        "load_graph_via_inc":"true"
    },
    "savedmodel-speaker_recognition_using_cnn":{
        "model_path":"keras-io/saved_model/speaker_recognition_using_cnn-savedmodel",
        "workload_path":"workload/PB",
        "execute_file":"speaker_recognition_using_cnn.py",
        "load_graph_via_inc":"true"
    },
    "savedmodel-timeseries_anomaly_detection":{
        "model_path":"keras-io/saved_model/timeseries_anomaly_detection-savedmodel",
        "workload_path":"workload/PB",
        "execute_file":"timeseries_anomaly_detection.py",
        "load_graph_via_inc":"true"
    },
    "savedmodel-timeseries_classification_from_scratch":{
        "model_path":"keras-io/saved_model/timeseries_classification_from_scratch-savedmodel",
        "workload_path":"workload/PB",
        "execute_file":"timeseries_classification_from_scratch.py",
        "load_graph_via_inc":"true"
    },
    "savedmodel-bayesian_neural_networks":{
        "model_path":"keras-io/saved_model/bayesian_neural_networks-savedmodel",
        "workload_path":"workload/PB",
        "execute_file":"bayesian_neural_networks.py",
        "load_graph_via_inc":"true"
    },
    "savedmodel-deep_q_network_breakout":{
        "model_path":"keras-io/saved_model/deep_q_network_breakout-savedmodel",
        "workload_path":"workload/PB",
        "execute_file":"deep_q_network_breakout.py",
        "load_graph_via_inc":"true"
    },
    "savedmodel-cyclegan":{
        "model_path":"keras-io/saved_model/cyclegan-savedmodel",
        "workload_path":"workload/PB",
        "execute_file":"cyclegan.py",
        "load_graph_via_inc":"true"
    },
    "savedmodel-transformer_asr":{
        "model_path":"keras-io/saved_model/transformer_asr-savedmodel",
        "workload_path":"workload/PB",
        "execute_file":"transformer_asr.py",
        "load_graph_via_inc":"true"
    },
    "savedmodel-text_extraction_with_bert":{
        "model_path":"keras-io/saved_model/text_extraction_with_bert-savedmodel",
        "workload_path":"workload/PB",
        "execute_file":"text_extraction_with_bert.py",
        "load_graph_via_inc":"true"
    },

    "frozen-antirectifier":{
        "model_path":"keras-io/saved_model/antirectifier-frozen",
        "workload_path":"workload/PB",
        "execute_file":"antirectifier.py",
        "load_graph_via_inc":"true"
    },
    "frozen-autoencoder":{
        "model_path":"keras-io/saved_model/autoencoder-frozen",
        "workload_path":"workload/PB",
        "execute_file":"autoencoder.py",
        "load_graph_via_inc":"true"
    },
    "frozen-collaborative_filtering_movielens":{
        "model_path":"keras-io/saved_model/collaborative_filtering_movielens-frozen",
        "workload_path":"workload/PB",
        "execute_file":"collaborative_filtering_movielens.py",
        "load_graph_via_inc":"true"
    },
    "frozen-ddpg_pendulum":{
        "model_path":"keras-io/saved_model/ddpg_pendulum-frozen",
        "workload_path":"workload/PB",
        "execute_file":"ddpg_pendulum.py",
        "load_graph_via_inc":"true"
    },
    "frozen-deep_neural_decision_forests":{
        "model_path":"keras-io/saved_model/deep_neural_decision_forests-frozen",
        "workload_path":"workload/PB",
        "execute_file":"deep_neural_decision_forests.py",
        "load_graph_via_inc":"true"
    },
    "frozen-image_classification_with_vision_transformer":{
        "model_path":"keras-io/saved_model/image_classification_with_vision_transformer-frozen",
        "workload_path":"workload/PB",
        "execute_file":"image_classification_with_vision_transformer.py",
        "load_graph_via_inc":"true"
    },
    "frozen-keypoint_detection":{
        "model_path":"keras-io/saved_model/keypoint_detection-frozen",
        "workload_path":"workload/PB",
        "execute_file":"keypoint_detection.py",
        "load_graph_via_inc":"true"
    },
    "frozen-mnist_convnet":{
        "model_path":"keras-io/saved_model/mnist_convnet-frozen",
        "workload_path":"workload/PB",
        "execute_file":"mnist_convnet.py",
        "load_graph_via_inc":"true"
    },
    "frozen-neural_style_transfer":{
        "model_path":"keras-io/saved_model/neural_style_transfer-frozen",
        "workload_path":"workload/PB",
        "execute_file":"neural_style_transfer.py",
        "load_graph_via_inc":"true"
    },
    "frozen-node2vec_movielens":{
        "model_path":"keras-io/saved_model/node2vec_movielens-frozen",
        "workload_path":"workload/PB",
        "execute_file":"node2vec_movielens.py",
        "load_graph_via_inc":"true"
    },
    "frozen-quasi_svm":{
        "model_path":"keras-io/saved_model/quasi_svm-frozen",
        "workload_path":"workload/PB",
        "execute_file":"quasi_svm.py",
        "load_graph_via_inc":"true"
    },
    "frozen-semantic_similarity_with_bert":{
        "model_path":"keras-io/saved_model/semantic_similarity_with_bert-frozen",
        "workload_path":"workload/PB",
        "execute_file":"semantic_similarity_with_bert.py",
        "load_graph_via_inc":"true"
    },
    "frozen-speaker_recognition_using_cnn":{
        "model_path":"keras-io/saved_model/speaker_recognition_using_cnn-frozen",
        "workload_path":"workload/PB",
        "execute_file":"speaker_recognition_using_cnn.py",
        "load_graph_via_inc":"true"
    },
    "frozen-timeseries_anomaly_detection":{
        "model_path":"keras-io/saved_model/timeseries_anomaly_detection-frozen",
        "workload_path":"workload/PB",
        "execute_file":"timeseries_anomaly_detection.py",
        "load_graph_via_inc":"true"
    },
    "frozen-timeseries_classification_from_scratch":{
        "model_path":"keras-io/saved_model/timeseries_classification_from_scratch-frozen",
        "workload_path":"workload/PB",
        "execute_file":"timeseries_classification_from_scratch.py",
        "load_graph_via_inc":"true"
    },
    "frozen-bayesian_neural_networks":{
        "model_path":"keras-io/saved_model/bayesian_neural_networks-frozen",
        "workload_path":"workload/PB",
        "execute_file":"bayesian_neural_networks.py",
        "load_graph_via_inc":"true"
    },
    "frozen-deep_q_network_breakout":{
        "model_path":"keras-io/saved_model/deep_q_network_breakout-frozen",
        "workload_path":"workload/PB",
        "execute_file":"deep_q_network_breakout.py",
        "load_graph_via_inc":"true"
    },
    "frozen-cyclegan":{
        "model_path":"keras-io/saved_model/cyclegan-frozen",
        "workload_path":"workload/PB",
        "execute_file":"cyclegan.py",
        "load_graph_via_inc":"true"
    },
    "frozen-transformer_asr":{
        "model_path":"keras-io/saved_model/transformer_asr-frozen",
        "workload_path":"workload/PB",
        "execute_file":"transformer_asr.py",
        "load_graph_via_inc":"true"
    },
    "frozen-text_extraction_with_bert":{
        "model_path":"keras-io/saved_model/text_extraction_with_bert-frozen",
        "workload_path":"workload/PB",
        "execute_file":"text_extraction_with_bert.py",
        "load_graph_via_inc":"true"
    },
    "DCN":{
        "model_path":"config/dcn.config",
        "workload_path":"workload/EasyRec"
    },
    "BST":{
        "model_path":"config/bst.config",
        "workload_path":"workload/EasyRec"
    },
    "DBMTL":{
        "model_path":"config/dbmtl.config",
        "workload_path":"workload/EasyRec"
    },
    "MIND":{
        "model_path":"config/mind.config",
        "workload_path":"workload/EasyRec"
    },
    "MMoE":{
        "model_path":"config/mmoe.config",
        "workload_path":"workload/EasyRec"
    },
    "DeepFM":{
        "model_path":"config/deepfm.config",
        "workload_path":"workload/EasyRec"
    },
    "DSSM":{
        "model_path":"config/dssm.config",
        "workload_path":"workload/EasyRec"
    },
    "ESMM":{
        "model_path":"config/esmm.config",
        "workload_path":"workload/EasyRec"
    },
    "DeepID":{
        "workload_path":"workload/DeepID"
    },

    "resnet34_tf_22_1":{
        "model_path":"intel-models/ssd_resnet34/ssd_resnet34_mAP_20.2.pb",
        "workload_path":"workload/PB"
    },

    "Yolov4-tf":{
        "model_path":"Yolov4/frozen_darknet_yolov4_model.pb",
        "workload_path":"workload/PB"
    },
    "Yolov5":{
        "model_path":"Yolov5/savedmodel",
        "workload_path":"workload/PB",
        "load_graph_via_inc":"true"
    },
    "convnext_xlarge_21k_224_1":{
        "model_path":"tensorflow-hub/convnext_xlarge_21k_224_1",
        "workload_path":"workload/PB",
        "load_graph_via_inc":"true"
    },
    "nnlm-en-dim128_2":{
        "model_path":"tensorflow-hub/nnlm-en-dim128_2",
        "workload_path":"workload/PB",
        "load_graph_via_inc":"true"
    },
    "enformer_1":{
        "model_path":"tensorflow-hub/enformer_1",
        "workload_path":"workload/PB",
        "load_graph_via_inc":"true"
    },
    "wav2vec2_1":{
        "model_path":"tensorflow-hub/wav2vec2_1",
        "workload_path":"workload/PB",
        "load_graph_via_inc":"true"
    },
    "ssd_mobilenet_v2":{
        "model_path":"tensorflow-hub/ssd_mobilenet_v2",
        "workload_path":"workload/PB",
        "load_graph_via_inc":"true"
    },
    "talkheads_ggelu_bert_en_base_2":{
        "model_path":"tensorflow-hub/talkheads_ggelu_bert_en_base_2",
        "workload_path":"workload/PB",
        "load_graph_via_inc":"true"
    },
    "mobilebert_multi_cased_L-24_H-128_B-512_A-4_F-4_OPT":{
        "model_path":"tensorflow-hub/mobilebert_multi_cased_L-24_H-128_B-512_A-4_F-4_OPT",
        "workload_path":"workload/PB",
        "load_graph_via_inc":"true"
    },
    "retinanet_resnet50_v1_fpn_1024x1024_1":{
        "model_path":"tensorflow-hub/retinanet_resnet50_v1_fpn_1024x1024_1",
        "workload_path":"workload/PB",
        "load_graph_via_inc":"true"
    },
    "frozen-lstm_seq2seq":{
        "model_path":"keras-io/saved_model/s2s.frozen",
        "workload_path":"workload/PB",
        "load_graph_via_inc":"true"
    },
    "savedmodel-nlp_image_search":{
        "model_path":"keras-io/saved_model/nl_image_search.savedmodel",
        "workload_path":"workload/PB",
        "load_graph_via_inc":"true"
    },
    "frozen-fnet":{
        "model_path":"keras-io/saved_model/fnet.frozen",
        "workload_path":"workload/PB",
        "load_graph_via_inc":"true"
    },
    "frozen-traffic_forcast":{
        "model_path":"keras-io/saved_model/traffic-forcast.frozen",
        "workload_path":"workload/PB",
        "load_graph_via_inc":"true"
    },
    "frozen-anomaly_detection":{
        "model_path":"keras-io/saved_model/anomaly-detection.frozen",
        "workload_path":"workload/PB",
        "load_graph_via_inc":"true"
    },
    "frozen-ESPCN":{
        "model_path":"keras-io/saved_model/ESPCN.frozen",
        "workload_path":"workload/PB",
        "load_graph_via_inc":"true"
    },
    "keras-PointNet":{
        "model_path":"keras-io/models/pointnet.pb",
        "workload_path":"workload/PB"
    },
    "keras-ViTS":{
        "model_path":"examples/vision",
        "workload_path":"workload/keras",
        "execute_file":"shiftvit.py"
    },
    "Xception":{
        "model_source": "https://keras.io/api/applications/xception/",
        "model_path":"keras-io/saved_model/Xception/Xception-frozen",
        "workload_path":"workload/PB",
        "load_graph_via_inc":"true"
    }
 }
